<meta charset="utf-8" emacsmode="-*- markdown -*"> 
                            **Welcome!**

![ ](louie1.jpg width="180px")

About
===============================================================================

My name is Matthew Baca, and I am a PhD student studying statistics at the University of Wisconsin.  I got my Bachelor of Science (BS) in Mathematics from the New Mexico Institute of Mining and Technology (NMT) and my Master of Science (MS) in Biostatistics from the Washington University School of Medicine in St. Louis.  For three years I worked for the Navy at China Lake, where I was doing statistical analysis and tool development in the world of Modeling and Simulation (M&S).  At China Lake I had developed several interests in data science and statistics.

Currently my interest include: (1) Design of Experiments, (2) incorporating statistical rigor to the Verification and Validation (V&V) process, (3) time series analysis, (4) tool/software development, and (5) mixed effects/regression modeling.

Of the many topics in data science, "causal inference", is a common term that I keep hearing about.  Other than "X causes Y" I do not know much about causal inference, and I would like to learn more.  I would like to learn about causal inference because I am interested in its application to computer models and simulations.

Homework-2
===============================================================================

**Problem**

In the, [Assessing Time-Varying Causal Effect Moderation in Mobile Health](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6241330/), paper, the authors wanted to know if the use of Mobile Health (mHealth) interventions over time can help reduce heavy drinking and smoking among college students.  Being able to curb the urge to drink heavily and/or smoke among students is important to help them not only be healthy but also prematurely prevent any alcohol and cigarette addictions.

**Variables**

Here is our treatment effect is $A_t$.  When, $A_t = 1$, then a mindfulness message is provided at the $t$ th treatment occasion, otherwise $A_t = 0$.  We also have $\bar{A_t} = (A_1, â€¦, A_t)$ which includes a sequence of random variables or realized values up to a specific treatment occasion.  The "bar" notation can be applied to other variables, $X$ and $Y$.  The response variable is, $Y_{t+1}$, which is the smoking rate between the occasion $t$ self-report and the following self-report.  The variable, $X_t$, contains summaries of previous measurements of context.  $X_t$ includes the time of day, number of reports recently completed, prior smoking rate, current need to self-regulate, baseline smoking severity, baseline drinking level, age, gender, and other summary variables formed from the reports up to and including the $t$ th occasion.  Lastly we have our history variable, $H_t = (\bar{X}_t, \bar{Y}_t, \bar{A}_{t - 1})$, which is our information accrued up to treatment occasion $t$.

**Causal Effects**

Our causal effect is,

$$
\mathbb{E}[Y_{t + 1}(\bar{A}_{t - 1}, 1) - Y_{t + 1}(\bar{A}_{t - 1}, 0) | S_{1t}(\bar{A}_{t - 1})]
$$

where $S_{1t}(\bar{A}_{t - 1})$ is a vector of summary variables chosen from $H_t(\bar{A}_{t - 1})$.  This causal effect represents the difference between effect of $A_t = 1$ (mindfulness message treatment) versus $A_t = 0$ on the smoking rate response at $t + 1$ given $S_{1t}(\bar{A}_{t - 1})$.  Here, $S_{1t}(\bar{A}_{t - 1})$, addresses a variety of scientific questions.

**Hypothesis**

The hypothesis here is that mindfulness message treatments over time will curb college students heavy drinking and smoking rates.

Homework-3
===============================================================================

**SWIG**

Below is a SWIG diagram/relationship graph between the variables, $A_t, X_t,$ and $Y_t$.  This diagram is for the first three time points, $t = (1, 2, 3)$.  For the remainder of this project we will only consider these first three time points.

![ ](swig1.jpg)

**Assumptions**

Our first assumption is of exchangeability, i.e. $Y(a) \perp \!\!\! \perp A$ for $a \in A$.  We can make this assumption because knowing that person $i$ has been assigned treatment $a = 1$ gives no information on the smoking rate, $Y$, of person $j$ who has been assigned to treatment $a = 0$.  The assumption of SUTVA where that $a \mapsto Y(a)$ is well defined is also being made.  We can make this assumptions because we are assuming that $a = 1$ reduces smoking rate $Y(a)$ while $a = 0$ does not.  The assumption of positivity $\mathbb{P}(A = a) \in (0, 1)$ is also being made.  We can make this assumption because our subjects are either being assigned the mindfullness treatment or not i.e. $a = 1$ or $a = 0$.  

The assumption of conditional positivity is also being made where $\mathbb{P}(A_t = a_t | S_t) \in (0, 1)$, where $S_t$ is a function of, $\bar{A}_{t-1}, \bar{X}_{t}$, and $\bar{Y}_{t}$ variables.  The assumption of conditional exchangeability i.e. $A \perp \!\!\! \perp Y(a)|S$ is also being made.  Lastly the assumption of $\mathbb{P}(S) > 0$ is being made sense the histories of $A, X,$ and $Y$ are all non zero.

**Theorem 3.1**
Given positivity, SUTVA, and exchangeability, then

$$
\mathbb{E}[Y(a)] = \mathbb{E}[Y|A = a]
$$

**Theorem 3.2**
Assume conditional positivity, conditional exchangeability, and $\mathbb{P}(X \in C) > 0$ where $C \in \mathbb{R}^d$, then

$$
\mathbb{E}[Y(a) | X \in C] = \mathbb{E}[Y | A = a, X \in C]
$$

**Identification**

Identification will be done for the first three time points, $t$, on the following casual effect,

\begin{equation}
\mathbb{E}[Y_{t+1}(\bar{A}_{t-1}, 1) - Y_{t+1}(\bar{A}_{t-1}, 0) | S_t(\bar{A}_{t-1})]
\end{equation}


where $S_t$ is a function of $\bar{A}_{t-1}, \bar{X}_{t},$ and $\bar{Y}_{t}$.

***Case 1:***

For case 1 we look at the first time point when $t = 1$.  Below we can see the SWIG for when $t = 1$.

![ ](swig1case1.jpg)

For $t = 1$ our casual effect becomes,

\begin{align*}
\mathbb{E}[Y_2(1) - Y_2(0)]
\end{align*}

Sense we do not have any history on $X, A$, or $Y$ yet, our $S_1$ function does not exhist.  From SUTVA and Theorem 3.1 we get,

\begin{align*}
\mathbb{E}[Y_2(1) - Y_2(0)|S_1] = \mathbb{E}[Y_2|S_1, A_1 = 1] - \mathbb{E}[Y_2|S_1, A_1 = 0]
\end{align*}

***Case 2:***

For case 2 we look at the second time point when $t = 2$.  Below we can see the SWIG for when $t = 2$.

![ ](swig1case2.jpg)

For $t = 2$ our casual effect becomes,

\begin{align*}
\mathbb{E}[Y_3(a_1, 1) - Y_3(a_1, 0)|S_2]
\end{align*}

We can get,

\begin{align*}
\mathbb{E}[Y_3(a_1, 1)|S_2] = \mathbb{E}[\mathbb{E}[Y_3(a_1, 1)|S_2, X_2(a_1), Y_2(a_1)]]
\end{align*}

Let,

\begin{align*}
g(X_2(a_1), Y_2(a_1))= \mathbb{E}[Y_3(a_1, 1)|S_2, X_2(a_1), Y_2(a_1)]
\end{align*}

By Theorem 3.1 our effect becomes,

\begin{align}
\mathbb{E}[g(X_2(a_1), Y_2(a_1))] = \mathbb{E}[g(X_2, Y_2)| A_1 = a_1]
\end{align}

By Theorem 3.2 our $g(X_2(a_1), Y_2(a_1))$ becomes,

\begin{align*}
g(X_2(a_1), Y_2(a_1)) &= g(x, y) \\
&= \mathbb{E}[Y_3(a_1, 1)|S_2, X_2(a_1) = x, Y_2(a_1) = y] \\
&= \mathbb{E}[Y_3|S_2, X_2(a_1) = x, Y_2(a_1) = y, A_1 = a_1, A_2 = 1]
\end{align*}

Plugging this back into (2) we then get,

\begin{align*}
\mathbb{E}[Y_3(a_1, 1)|S_2] = \mathbb{E}[\mathbb{E}[Y_3|S_2, X_2, Y_2, A_1 = a_1, A_2 = 1]| A_1 = a_1]
\end{align*}

Similar we can get,

\begin{align*}
\mathbb{E}[Y_3(a_1, 0)|S_2] = \mathbb{E}[\mathbb{E}[Y_3|S_2, X_2, Y_2, A_1 = a_1, A_2 = 0]| A_1 = a_1]
\end{align*}

Via SUTVA and Theorem 3.2 our casual effect becomes,

\begin{align*}
&\mathbb{E}[Y_3(a_1, 1) - Y_3(a_1, 0)|S_2] \\
&= \mathbb{E}[Y_3(a_1, 1)|S_2] - \mathbb{E}[Y_3(a_1, 0)|S_2] \\
&= \mathbb{E}[\mathbb{E}[Y_3|S_2, X_2, Y_2, A_1 = a_1, A_2 = 1]| A_1 = a_1] \\
&- \mathbb{E}[\mathbb{E}[Y_3|S_2, X_2, Y_2, A_1 = a_1, A_2 = 0]| A_1 = a_1]
\end{align*}

***Case 3:***

For case 3 we look at the third time point when $t = 3$.  Below we can see the SWIG for when $t = 3$.

![ ](swig1case3.jpg)

For $t = 3$ our casual effect becomes,

\begin{align*}
\mathbb{E}[Y_4(a_1, a_2, 1) - Y_4(a_1, a_2, 0)|S_3]
\end{align*}

We can get,

\begin{align*}
\mathbb{E}[Y_4(a_1, a_2, 1)|S_3] = \mathbb{E}[\mathbb{E}[Y_4(a_1, a_2, 1)|S_3, X_3(a_1, a_2), Y_3(a_1, a_2)]]
\end{align*}

Let,

\begin{align*}
g(X_3(a_1, a_2), Y_3(a_1, a_2))= \mathbb{E}[Y_3(a_1, a_2, 1)|S_3, X_3(a_1, a_2), Y_3(a_1, a_2)]
\end{align*}

By Theorem 3.1 our effect becomes,

\begin{align}
\mathbb{E}[g(X_3(a_1, a_2), Y_3(a_1, a_2))] = \mathbb{E}[g(X_3, Y_3)| A_1 = a_1, A_2 = a_2]
\end{align}

By Theorem 3.2 our $g(X_3(a_1, a_2), Y_3(a_1, a_2))$ becomes,

\begin{align*}
g(X_3(a_1, a_2), Y_3(a_1, a_2)) &= g(x, y) \\
&= \mathbb{E}[Y_4(a_1, a_2, 1)|S_3, X_3(a_1, a_2) = x, Y_3(a_1, a_2) = y] \\
&= \mathbb{E}[Y_4|S_3, X_3(a_1, a_2) = x, Y_3(a_1, a_2) = y, A_1 = a_1, A_2 = a_2, A_3 = 1]
\end{align*}

Plugging this back into (3) we then get,

\begin{align*}
\mathbb{E}[Y_4(a_1, a_2, 1)|S_3] = \mathbb{E}[\mathbb{E}[Y_4|S_3, X_3, Y_3, A_1 = a_1, A_2 = a_2, A_3 = 1]| A_1 = a_1, A_2 = a_2]
\end{align*}

Similar we can get,

\begin{align*}
\mathbb{E}[Y_4(a_1, a_2, 0)|S_3] = \mathbb{E}[\mathbb{E}[Y_4|S_3, X_3, Y_3, A_1 = a_1, A_2 = a_2, A_3 = 0]| A_1 = a_1, A_2 = a_2]
\end{align*}

Via SUTVA and Theorem 3.2 our casual effect becomes,

\begin{align*}
&\mathbb{E}[Y_4(a_1, a_2, 1) - Y_4(a_1, a_2, 0)|S_3] \\
&= \mathbb{E}[Y_4(a_1, a_2, 1)|S_3] - \mathbb{E}[Y_4(a_1, a_2, 0)|S_3] \\
&= \mathbb{E}[\mathbb{E}[Y_4|S_3, X_3, Y_3, A_1 = a_1, A_2 = a_2, A_3 = 1]| A_1 = a_1, A_2 = a_2] \\
&- \mathbb{E}[\mathbb{E}[Y_4|S_3, X_3, Y_3, A_1 = a_1, A_2 = a_2, A_3 = 0]| A_1 = a_1, A_2 = a_2]
\end{align*}

**Remarks**

For $t = 1$, the identification of our casual effect only needs the first assigned treatment values of $A_1 = 1$ and $A_1 = 0$.  Next, for the second time point, $t = 2$, the identification of our casual effects needs, $S_2$, which is a function of $X_1, A_1$, and $Y_2$.  Also the previous treatment variables, $A_1 = a_1$ is needed.  The newly assigned treatment values of $A_2 = 1$ and $A_2 = 0$ are needed.  Lastly the identification needs the previous response variable, $Y_2$, and the previous summary variable, $X_2$.  For the third time point, $t = 3$, the identification of our casual effects needs, $S_3$ which is a function of all previous $X, A,$ and $Y$.  Also the previous treatment variables, $A_1 = a_1$ and $A_2 = a_2$ are needed.  The newly assigned treatment values of $A_3 = 1$ and $A_3 = 0$ are needed.  Lastly the identification needs the previous response variable, $Y_3$, and the previous summary variable, $X_3$.

Homework-4
===============================================================================

Outcome regression adjusting for propensity score will be used to estimate our casual estimate.  We are assuming that $X$ is measured and satisfies backdoor criteria.  Also, the assumption of $Y(a)$ being well-defined (SUTVA) is being made.  Lastly the assumption of positivity for $Y(a)$ is being made.  Sense data is not available, only pseudo code will be provided for our estimation techniques.  Because our data is longitudinal the estimation pseudo code will only be shown for the first three time points. 

***Case 1:***

Here our time point is at $t = 1$ and below is our casual estimate,

\begin{align}
\mathbb{E}[Y_2(1) - Y_2(0)|S_1] = \mathbb{E}[Y_2|S_1, A_1 = 1] - \mathbb{E}[Y_2|S_1, A_1 = 0]
\end{align}

Our data set is,

$$D = [Y_2, A_1, S_1]$$

Next we need to estimate our propensity score.  This is done by regressing $A_1$ onto $S_1$ via GLM with a logit link function.  

```
mod = fitglm(D, A1 ~ S1, "binomial")
```

Then we make our predictions,

```
p = predict(mod, D)
```

Next we build linear splines with propensity scores and knots at quantiles.  The propensity scores and splines are added to the data, $D$.

```
D$p = p
q = quantile(p, [0.25, 0.5, 0.75])
D$p1 = (p >= q(1)) * (p - q(1))
D$p2 = (p >= q(2)) * (p - q(2))
D$p3 = (p >= q(3)) * (p - q(3))
```

Now we build our outcome regression model with $A_1$.

```
mod = fitglm(D, Y2 ~ A1 + p + p1 + p2 + p3)
```

We can now estimate (4) with the coefficient for $A_1$ from the outcome regression model above.

***Case 2:***

Here our time point is at $t = 2$ and below is our casual estimate,

\begin{align}
&\mathbb{E}[Y_3(a_1, 1) - Y_3(a_1, 0)|S_2] \nonumber \\
&= \mathbb{E}[\mathbb{E}[Y_3|S_2, X_2, Y_2, A_1 = a_1, A_2 = 1]| A_1 = a_1] \nonumber \\
&- \mathbb{E}[\mathbb{E}[Y_3|S_2, X_2, Y_2, A_1 = a_1, A_2 = 0]| A_1 = a_1]
\end{align}

Our data set is,

$$D = [Y_3, Y_2, X_2, S_2, A_1, A_2]$$

Next we need to estimate our propensity score.  This is done by regressing $A_2$ onto $A_1, Y_2, X_2,$ and $S_2$ via GLM with a logit link function.  

```
mod = fitglm(D, A2 ~ A1 + Y2 + X2 + S2, "binomial")
```

Then we make our predictions,

```
p = predict(mod, D)
```

Next we build linear splines with propensity scores and knots at quantiles.  The propensity scores and splines are added to the data, $D$.

```
D$p = p 
q = quantile(p, [0.25, 0.5, 0.75]) 
D$p1 = (p >= q(1)) * (p - q(1)) 
D$p2 = (p >= q(2)) * (p - q(2)) 
D$p3 = (p >= q(3)) * (p - q(3))
```

Now we build our outcome regression model with $A_2$.

```
mod = fitglm(D, Y3 ~ A2 + p + p1 + p2 + p3)
```

We can now estimate (5) with the coefficient for $A_2$ from the outcome regression model above.

***Case 3:***

Here our time point is at $t = 3$ and below is our casual estimate,

\begin{align}
&\mathbb{E}[Y_4(a_1, a_2, 1) - Y_4(a_1, a_2, 0)|S_3] \nonumber \\
&= \mathbb{E}[\mathbb{E}[Y_4|S_3, X_3, Y_3, A_1 = a_1, A_2 = a_2, A_3 = 1]| A_1 = a_1, A_2 = a_2] \nonumber \\
&- \mathbb{E}[\mathbb{E}[Y_4|S_3, X_3, Y_3, A_1 = a_1, A_2 = a_2, A_3 = 0]| A_1 = a_1, A_2 = a_2]
\end{align}

Our data set is,

$$D = [Y_4, Y_3, X_3, S_3, A_1, A_2, A_3]$$

Next we need to estimate our propensity score.  This is done by regressing $A_3$ onto $A_1, A_2, Y_3, X_3,$ and $S_3$ via GLM with a logit link function.  

```
mod = fitglm(D, A3 ~ A1 + A2 + Y3 + X3 + S3, "binomial")
```

Then we make our predictions,

```
p = predict(mod, D)
```

Next we build linear splines with propensity scores and knots at quantiles.  The propensity scores and splines are added to the data, $D$.

```
D$p = p 
q = quantile(p, [0.25, 0.5, 0.75]) 
D$p1 = (p >= q(1)) * (p - q(1)) 
D$p2 = (p >= q(2)) * (p - q(2)) 
D$p3 = (p >= q(3)) * (p - q(3))
```

Now we build our outcome regression model with $A_3$.

```
mod = fitglm(D, Y4 ~ A3 + p + p1 + p2 + p3)
```

We can now estimate (6) with the coefficient for $A_3$ from the outcome regression model above.

Homework-5
===============================================================================

Two sensitivity methods will be used for this project.  The first is that Manski monotone bounds will be created for the casual estimates.  Secondly a permutation test on the association between treatment $A = 1$ and no treatment $A = 0$ on the smoking rate $Y$ will be done.

**Assumptions**

For sensitivity analysis additional assumptions are being made.  The original assumptions are described above in *3 Homework-3*.  Here we will be assuming,

\begin{align*}
  Y(a) \perp \!\!\! \perp A | X, U
\end{align*}

Where $X$ is measured but $U$ is not.  Next we be assuming positivity where,

\begin{align*}
  0 < \mathbb{P}(A = 1 | X = x, U = u) < 1
\end{align*}

Now in order to construct Manski bounds we need to assume that the individual treatment response is monotone i.e. $Y(1) \ge Y(0)$.  Sense we are assuming that when an individual is treated $A = 1$ the smoking rate response $Y(1)$ should go down.  Therefore we have $Y(0) \ge Y(1)$.  So we will need to switch $A$ with $1 - A$ to have this monotone feature.  Another monotone assumption we need is,

\begin{align*}
  \mathbb{E}[Y(a) | A = 0, X = x] \ge \mathbb{E}[Y(a) | A = 1, X = x]
\end{align*}

**Alternatives to Estimation/Implementation/Identification**

Originally we were not assuming any unmeasured $U$ within our experiment.  Now we are making this assumption because it is highly possible that there are some unmeasured factors that could be effecting our casual effects i.e. circle of friends that encourage drinking/smoking, depression and so on.

Another estimation method to look into is using Generalized Estimating Equations (GEE).  This method could be useful because it incorporates the, $t$, time points and we will not have to make casual estimates at every time point $t$.

**Sensitivity Analysis Pseudo Code/Algorithm**

Below are the descriptions for calculating the Manski bounds and the permutation test for the first $t = (1, 2, 3)$ time points.

***Case 1:***

For the first time point, $t = 1$, we will find the Manski bounds for casual estimate in (4).  Here the data is,

$$D = [Y_2, A_1, S_1]$$

1.  Calculate the Manksi upper bound
```
U = mean(D$Y2[D$A1 == 0]) - mean(D$Y2[D$A1 == 1])
```

2.  Calculate the Manski bounds
```
bounds = c(0, u)
```

3.  Conduct permutation test

  1.  Estimate $E^*$ via (4) using original data $D$ 
  2.  Create $A_1^*$ by randomly permuting $A_1$ 
  3.  Recalculate the casual estimate (4) using $A_1^*$ and save into vector $E$. 
  4.  Repeat b-c a total of $B$ (large number) of times 
  5.  Calculate p-value = sum($E \ge E^*$) / $B$ 

Lastly with the calculated p-value we reject or accept the null hypothesis $H_0$ that there is no association.  Because there is a total of $T$ comparisons being made a Bonferroni correction will be needed to address the issue of multiple comparisons i.e. compare the p-value to $\alpha / T$ instead of $\alpha$ where $T$ is the total number of time points.

***Case 2:***

For the second time point, $t = 2$, we will find the Manski bounds for casual estimate in (5).  Here the data is,

$$D = [Y_2, Y_3, X_2, A_1, A_2, S_2]$$

1.  Calculate the Manksi upper bound
```
U = mean(D$Y3[D$A2 == 0]) - mean(D$Y3[D$A2 == 1])
```

2.  Calculate the Manski bounds
```
bounds = c(0, u)
```

3.  Conduct permutation test

  1.  Estimate $E^*$ via (5) using original data $D$
  2.  Create $A_2^*$ by randomly permuting $A_2$
  3.  Recalculate the casual estimate (5) using $A_2^*$ and save into vector $E$.
  4.  Repeat b-c a total of $B$ (large number) of times
  5.  Calculate p-value = sum($E \ge E^*$) / $B$

Lastly with the calculated p-value we reject or accept the null hypothesis $H_0$ that there is no association.  Because there is a total of $T$ comparisons being made a Bonferroni correction will be needed to address the issue of multiple comparisons i.e. compare the p-value to $\alpha / T$ instead of $\alpha$ where $T$ is the total number of time points.

***Case 3:***

For the third time point, $t = 3$, we will find the Manski bounds for casual estimate in (6).  Here the data is,

$$D = [Y_3, Y_4, X_3, A_1, A_2, A_3, S_3]$$

1.  Calculate the Manksi upper bound
```
U = mean(D$Y4[D$A3 == 0]) - mean(D$Y4[D$A3 == 1])
```

2.  Calculate the Manski bounds
```
bounds = c(0, u)
```

3.  Conduct permutation test

  1.  Estimate $E^*$ via (6) using original data $D$
  2.  Create $A_3^*$ by randomly permuting $A_3$
  3.  Recalculate the casual estimate (6) using $A_3^*$ and save into vector $E$.
  4.  Repeat b-c a total of $B$ (large number) of times
  5.  Calculate p-value = sum($E \ge E^*$) / $B$

Lastly with the calculated p-value we reject or accept the null hypothesis $H_0$ that there is no association.  Because there is a total of $T$ comparisons being made a Bonferroni correction will be needed to address the issue of multiple comparisons i.e. compare the p-value to $\alpha / T$ instead of $\alpha$ where $T$ is the total number of time points.

**Violation of Assumptions**

If my assumptions were violated then I would have to change my estimation process and would most likely have to use GEE to estimate my casual effects.  I also would not be able to use Manksi monotone bounds would have to look into other methods such as Rosenbaum or VanderWeele.  Although if my assumptions were violated I would still be able to use the permutation method to test the null hypothesis that there is no association between treatment and no treatment on smoking rate.

**Un-testable Assumptions**

There are several assumptions that can not be tested or are very difficult to test.  One assumptions is conditional positivity and another assumption is conditional exchangeability.  The assumption of SUTVA is also hard/impossible to test.  Therefore my results depend on untestable assumptions: conditional positivity, conditional exchangeability, and SUTVA and this dependence is a limitation of our conclusions.


Lastly with the calculated p-value we reject or accept the null hypothesis $H_0$ that there is no association.


Homework-6
===============================================================================

**Final Remarks**

In summary we were set out to see if the use of Mobile Health interventions over time can help reduce heavy drinking and smoking among college students.  First we conducted identification of our casual estimate for the first three, $t = (1, 2, 3)$, time points.  Next, we calculated our casual estimates via outcome regression adjusting for propensity score. Then we conducted sensitivity analysis using Manksi monotone bounds and a permutation test on the association between treatment $A = 1$ and no treatment $A = 0$ on the smoking rate $Y$.  These methods were to be done for every, $t$, time point.  To avoid the need of running these methods a total of $T$ times, one could use Generalized Estimating Equations (GEE) which would incorporate the time component.  In the future I will look into the implementation of GEE to obtain our casual estimate.  One of the major limitations with this project is that we do not have any data and hopefully in the future I will have a longitudinal data set that I can try implement my analysis on.  As these healthcare APPs become more and more prevalent, this work can be used to test the effectiveness of these treatment intervention APPs over time.

<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
